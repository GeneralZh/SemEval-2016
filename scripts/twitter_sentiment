#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-

"""Script for predicting polarity classes of tweets.

The input file is assumed to be in TSV format where the second field
(starting with 0) is assumed to be the gold label and the last field
contains the text of the messages.

USAGE:
twitter_sentiment [MODE] [OPTIONS] [input_file]

@author = Wladimir Sidorenko (Uladzimir Sidarenka)
@mail = <sidarenk at uni dash potsdam dot de>
@version = 0.0.1

"""

##################################################################
# Imports
from __future__ import print_function, unicode_literals

from sentiment_classifier import SentimentClassifier
from evaluate import evaluate, get_fields, GLD_IDX, TXT_IDX
from preprocessing import ENCODING, NONMATCH_RE, iterlines, _cleanse

import argparse
import codecs
import os
import re
import sys

##################################################################
# Variables and Constants
# index of the topic field in the test file
TEST_TOPIC_IDX = 1

TRAIN = "train"
TEST = "test"
EVALUATE = "evaluate"

TAB = "\t"
TAB_RE = re.compile(TAB)

# Subjectivity Clues Lexicon
SUBJCL = "SubjectivityClues"
SUBJCL_W_IDX = 0                # index of a polar term
SUBJCL_SCORE_IDX = 1            # index of the score
SUBJCL_THRSHLD = 0              # minimum required absolute score

# HSAN dictionary (should be prefered)
HSAN = "HashtagSentimentAffLexNegLex"
HSAN_W_IDX = 0                # index of a polar term
HSAN_SCORE_IDX = 1              # index of the score
HSAN_THRSHLD = 4.               # minimum required absolute score
HSAN_NEG_RE = re.compile(r"(.*)(_neg(?:first)?)")

# Sentiment 140
S140 = "Sentiment140-Lexicon-v0.1"
S140_W_IDX = 0                  # index of a polar term
S140_SCORE_IDX = 1              # index of the score
S140_THRSHLD = 2.5              # minimum required absolute score
S140_NEG_RE = HSAN_NEG_RE
S140_STOP_WORDS = set(["out"])

# NRC Hashtag
NRC_HSHTAG = "NRC-Hashtag-Sentiment-Lexicon-v0.1"
NRC_HSHTAG_W_IDX = 0            # index of a polar term
NRC_HSHTAG_SCORE_IDX = 1        # index of the score
NRC_POSITIVE = "positive"
NRC_NEGATIVE = "negative"

# default lexicon entries
DFLT_POS = set([":)", ":-)", ":D", ":-D"])
DFLT_NEG = set([":(", ":-(", ":'("])

##################################################################
# Methods
def _add_cmn_options(a_parser):
    """Add common options to option subparser

    @param a_parser - option subparser

    @return \c void

    """
    a_parser.add_argument("-m", "--model",
                          help="path to the (stored or to be stored) model",
                          type=str)
    a_parser.add_argument("files", help="input files in TSV format",
                          type=argparse.FileType('r'),
                          nargs='*', default=[sys.stdin])


def _merge_lexica(a_lexica):
    """Read sentiment terms from lexicon file.

    Args:
    -----
      a_dname (tuple of 2 sets):
        list of positive and negative polar term sets

    Returns:
    --------
      (4-tuple): merges sets of positive and negative terms with their regexps

    """
    pos = set() | DFLT_POS
    neg = set() | DFLT_NEG
    for ipos, ineg in a_lexica:
        pos |= ipos
        neg |= ineg
        # if not pos:
        #     pos |= ipos
        # else:
        #     pos &= ipos
        # if not neg:
        #     neg |= ineg
        # else:
        #     neg &= ineg

    if pos:
        pos_re = re.compile(r"\b(" + "|".join([re.escape(t)
                                               for t in pos]) + r")(?=\s|\Z)")
    else:
        pos_re = NONMATCH_RE

    if neg:
        neg_re = re.compile(r"\b(" + "|".join([re.escape(t)
                                               for t in neg]) + r")(?=\s|\Z)")
    else:
        neg_re = NONMATCH_RE
    return (pos, pos_re, neg, neg_re)


def _read_lexicon(a_dname):
    """Read sentiment terms from lexicon file.

    Args:
    -----
      a_dname (str): path to the directory with lexicon files

    Returns:
    --------
      (2-tuple): sets of positive and negative terms

    """
    if not a_dname:
        return
    elif a_dname[-1] == '/':
        a_dname = os.path.dirname(a_dname)
    basename = os.path.basename(a_dname)
    if basename == HSAN:
        return _read_hsan(a_dname)
    elif basename == S140:
        return _read_s140(a_dname)
    elif basename == SUBJCL:
        return _read_subjcl(a_dname)
    elif basename == NRC_HSHTAG:
        return _read_nrc_hshtag(a_dname)
    else:
        raise Exception("Unknown dictionary format: '{:s}'".format(basename))


def _read_hsan(a_dname):
    """Read HashtagSentimentAffLexNegLex sentiment lexicon.

    Args:
    -----
      a_dname (str): path to the directory with lexicon files

    Returns:
    --------
      (2-tuple): sets of positive and negative terms

    """
    score = 0.
    term = ""
    fields = None
    pos = set()
    neg = set()
    print("Reading HashtagSentimentAffLexNegLex... ", end="", file=sys.stderr)
    # skip bigrams for the time being
    for fname in ["HS-AFFLEX-NEGLEX-unigrams.txt"]:
        fname = os.path.join(a_dname, fname)
        with codecs.open(fname, 'r', ENCODING) as ifile:
            for iline in ifile:
                iline = iline.strip()
                if not iline:
                    continue
                fields = TAB_RE.split(iline)
                score = float(fields[HSAN_SCORE_IDX])
                if abs(score) > HSAN_THRSHLD:
                    term = HSAN_NEG_RE.sub("not \1",
                                           _cleanse(fields[HSAN_W_IDX]))
                    if len(term) < 3:
                        continue
                    if score > 0.:
                        pos.add(term)
                    else:
                        neg.add(term)
    print("done", file=sys.stderr)
    return (pos, neg)


def _read_s140(a_dname):
    """Read Sentiment140-Lexicon-v0.1 sentiment lexicon.

    Args:
    -----
      a_dname (str): path to the directory with lexicon files

    Returns:
    --------
      (2-tuple): sets of positive and negative terms

    """
    score = 0.
    term = ""
    fields = None
    pos = set(); neg = set()
    print("Reading Sentiment140-Lexicon-v0.1... ", end = "", file = sys.stderr)
    for fname in ["unigrams-pmilexicon.txt"]: # skip bigrams for the time being
        fname = os.path.join(a_dname, fname)
        with codecs.open(fname, 'r', ENCODING) as ifile:
            for iline in ifile:
                iline = iline.strip()
                if not iline:
                    continue
                fields = TAB_RE.split(iline)
                score = float(fields[S140_SCORE_IDX])
                if abs(score) > S140_THRSHLD:
                    term = S140_NEG_RE.sub("not \1", _cleanse(fields[S140_W_IDX]))
                    if len(term) < 3 or term[0] == '@' or term in S140_STOP_WORDS:
                        continue
                    if score > 0.:
                        pos.add(term)
                    else:
                        neg.add(term)
    print("done", file = sys.stderr)
    return (pos, neg)

def _read_subjcl(a_dname):
    """Read SubjectiveClues sentiment lexicon.

    Args:
    -----
      a_dname (str): path to the directory with lexicon files

    Returns:
    --------
      (2-tuple): sets of positive and negative terms

    """
    pos = set()
    neg = set()
    score  = 0.
    term   = ""
    fields = None
    print("Reading Subjective Clues Lexicon... ", end="",
          file=sys.stderr)
    for fname in ["subjclueslen1-HLTEMNLP05.tff"]: # skip bigrams for the time being
        fname = os.path.join(a_dname, fname)
        with codecs.open(fname, 'r', ENCODING) as ifile:
            for iline in ifile:
                iline = iline.strip()
                if not iline:
                    continue
                fields = TAB_RE.split(iline)
                score = float(fields[SUBJCL_SCORE_IDX])
                if abs(score) > SUBJCL_THRSHLD:
                    term = _cleanse(fields[SUBJCL_W_IDX])
                    if not(term):
                        continue
                    elif score > 0.:
                        pos.add(term)
                    else:
                        neg.add(term)
    print("done", file = sys.stderr)
    return (pos, neg)

def _read_nrc_hshtag(a_dname):
    """Read NRC-Hashtag-Sentiment-Lexicon-v0.1 sentiment lexicon.

    Args:
    -----
      a_dname (str): path to the directory with lexicon files

    Returns:
    --------
      (2-tuple): sets of positive and negative terms

    """
    fields = None
    term = tclass = ""
    pos = set(); neg = set()
    print("Reading NRC-Hashtag-Sentiment-Lexicon-v0.1... ", end = "", file = sys.stderr)
    for fname in ["sentimenthashtags.txt"]: # skip bigrams for the time being
        fname = os.path.join(a_dname, fname)
        with codecs.open(fname, 'r', ENCODING) as ifile:
            for iline in ifile:
                iline = iline.strip()
                if not iline:
                    continue
                term, tclass = TAB_RE.split(iline)
                term = _cleanse(term)
                if not term:
                    continue
                if tclass == NRC_POSITIVE:
                    pos.add(term)
                elif tclass == NRC_NEGATIVE:
                    neg.add(term)
    print("done", file = sys.stderr)
    return (pos, neg)


def _read_dataset(a_files):
    """Read data set into a list of 2-tuples with input items and gold classes.

    @param a_files - input files containing training data

    @return list of 2-tuples with input items and their gold classes

    """
    return [(list(ifields[TXT_IDX]), ifields[GLD_IDX])
            for ifile in a_files for ifields in iterlines(ifile)]


def main():
    """Classify tweets according to their sentiment polarity

    @return \c 0 on success, non-0 other
    """
    # process CLI arguments
    argparser = argparse.ArgumentParser(description="""Script for classifying
tweets according to their sentiment polarity""")

    subparsers = argparser.add_subparsers(help="type of operation to perform", dest = "mode")
    # training options
    tr_parser = subparsers.add_parser(TRAIN, help = "train the model")
    tr_parser.add_argument("-d", "--dev-set", help = "development set",
                             type = argparse.FileType('r'))
    tr_parser.add_argument("-l", "--lexicon", help = "sentiment lexicon to use for sampling",
                           type = str, action = "append", default = [])
    _add_cmn_options(tr_parser)
    # testing options
    test_parser = subparsers.add_parser(TEST, help = "test the model")
    test_parser.add_argument("-d", "--debug", help = "output debug information", \
                             action = "store_true")
    test_parser.add_argument("-v", "--verbose", help = "output scores along with predicted labels",
                             action = "store_true")
    _add_cmn_options(test_parser)
    # evaluation options (train and test at the same time)
    ev_parser = subparsers.add_parser(EVALUATE, help = "evaluate trained model")
    _add_cmn_options(ev_parser)
    ev_parser.add_argument("-v", "--verbose", help = "output errors along with evaluation",
                           action = "store_true")
    args = argparser.parse_args()
    # perform the requied action
    if args.mode == TRAIN:
        classifier = SentimentClassifier(a_path = None)
        if args.dev_set is None:
            dev_set = None
        else:
            dev_set = _read_dataset([args.dev_set])
        lexica = [_read_lexicon(ilex) for ilex in args.lexicon]
        pos, pos_re, neg, neg_re = _merge_lexica(lexica)
        classifier.train(_read_dataset(args.files), a_path=args.model,
                         a_dev_set=dev_set, a_pos_re=pos_re, a_pos=pos,
                         a_neg_re=neg_re, a_neg=neg)
    elif args.mode == TEST:
        # load model from default location
        y = ""; score = 0.
        if args.model:
            classifier = SentimentClassifier(args.model)
        else:
            classifier = SentimentClassifier()
        for ifile in args.files:
            for ifields in iterlines(ifile, TEST_TOPIC_IDX):
                if args.debug:
                    classifier.debug(list(ifields[TXT_IDX]))
                else:
                    y, score = classifier.predict(list(ifields[TXT_IDX]))
                    if args.verbose:
                        ifields.append(str(score))
                    ifields.append(y)
                    print(TAB.join(ifields))
    else:
        raise NotImplementedError
        # for ifile in a_files:
        #     macro_MAE, micro_MAE = evaluate(classify(classifier, ifile), args.verbose, lambda x: x)
        #     print("{:20s}{:.7}".format("Macro-averaged MAE:", macro_MAE), file = sys.stderr)
        #     print("{:20s}{:.7}".format("Micro-averaged MAE:", micro_MAE), file = sys.stderr)
    return 0

##################################################################
# Main
if __name__ == "__main__":
    main()
