#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-

"""Script for predicting polarity classes of tweets.

The input file is assumed to be in TSV format where the second field
(starting with 0) is assumed to be the gold label and the last field
contains the text of the messages.

USAGE:
twitter_sentiment [MODE] [OPTIONS] [input_file]

@author = Wladimir Sidorenko (Uladzimir Sidarenka)
@mail = <sidarenk at uni dash potsdam dot de>
@version = 0.0.1

"""

##################################################################
# Imports
from __future__ import print_function, unicode_literals

from sentiment_classifier import SentimentClassifier
from evaluate import evaluate, get_fields, GLD_IDX, TXT_IDX
from twokenize import tokenize

import argparse
import re
import sys

##################################################################
# Variables and Constants
TRAIN = "train"
TEST = "test"
EVALUATE = "evaluate"
ENCODING = "utf-8"

POS_CHAR = ''
NEG_CHAR = ''
POS_RE = re.compile(r"[\b\A](amazing|better|best|cool||fun|fant|good|great|like|love|luv|wow|wonder\b|:\))")
NEG_RE = re.compile(r"\b(must|crush|satan|severe|hat[ei]|hein|barb|don't want)")

STOP_WORDS_RE = re.compile(r"\b(the(?:re)?|(?:any|every)body|here|from|an?|i[stn]|are|was|we(?:re)|ha[ds]|have|to|with|will|all|each|wh(?:en|re|o|at)(?:ever)?|may|might|i(?:'?m)?|that|the[my]|their|we\'?re|\'?s|through|by|been|this|as|going|do(?:es)?|did|about|[bmw]e|y?ou(?:rs?)?|u|some(?:thing|one)?|and|o[fr]|for|\'?(?:ve|d)|us|s?he|on|(?:some)?where|so|[ia]t|it\'?s|gonna|cc|\'?ll|may|take[ns]?|took|how|let|her|hi[ms]|my|(?:an)?other|g[eo]ts?|ac/dc|amazon|amazon\s+prime|amazon\s+prime\s+day|angela\s+merkel|apple|apple\s+watch|arsenal|barca|batman|bbc|bentley|bernie\s+sanders|beyonce|bobby\s+jindal|bob\s+marley|chelsea|chris\s+brown|conor\s+mcgregor|david\s+beckham|david\s+cameron|digi|disneyland|donald\s+trump|erdogan|eric\s+church|federer|fleetwood\s+mac|galaxy\s+note|game\s+of\s+thrones|google|google\+|grateful\s+dead|hannibal|harper|harry\s+potter|hillary|ibm|ihop|ios|ipad|iphone|ipod|jay-z|jeb\s+bush|joe\s+biden|jurassic\s+park|jurassic\s+world|justin|juventus|kerry|kurt\s+cobain|labor\s+day|lexus|madonna|magic\s+mike\s+xxl|mariah\s+carey|messi|metlife|what|can|either|[oi]nto|via|if|hi|one|two|-+|,+|[.%$]+)\b")
AMP_RE = re.compile(r"&amp;")
GT_RE = re.compile(r"&gt;")
LT_RE = re.compile(r"&lt;")
DIGIT_RE = re.compile(r"\b[\d:]+(?:[ap]\.?m\.|th|rd|nd|m|b)?\b")
HTTP_RE = re.compile(r"(?:https?://\S*|\b(?:(?:[\w]{3,5}://?|(?:www|bit)[.]|(?:\w[-\w]+[.])+(?:a(?:ero|sia|[c-gil-oq-uwxz])|b(?:iz|[abd-jmnorstvwyz])|c(?:at|o(?:m|op)|[acdf-ik-orsuvxyz])|d[dejkmoz]|e(?:du|[ceghtu])|f[ijkmor]|g(?:ov|[abd-ilmnp-uwy])|h[kmnrtu]|i(?:n(?:fo|t)|[del-oq-t])|j(?:obs|[emop])|k[eghimnprwyz]|l[abcikr-vy]|m(?:il|obi|useum|[acdeghk-z])|n(?:ame|et|[acefgilopruz])|o(?:m|rg)|p(?:ro|[ae-hk-nrstwy])|qa|r[eosuw]|s[a-eg-or-vxyz]|t(?:(?:rav)?el|[cdfghj-pr])|xxx)\b)(?:[^\s,.:;]|\.\w)*))")
AT_RE = re.compile(r"(RT\s+)?[.]?@\S+")
SPACE_RE = re.compile(r"\s\s+")

TAB = "\t"

##################################################################
# Methods
def _add_cmn_options(a_parser):
    """Add common options to option subparser

    @param a_parser - option subparser

    @return \c void

    """
    a_parser.add_argument("-m", "--model", help = "path to the (stored or to be stored) model", \
                              type = str)
    a_parser.add_argument("files", help = "input files in TSV format", \
                              type = argparse.FileType('r'), nargs = '*', default = [sys.stdin])

def _cleanse(a_line):
    """Remove spurious elements from line.

    @param a_line - line to be cleansed

    @return cleansed line

    """
    line = AT_RE.sub("", HTTP_RE.sub("", a_line.lower()))
    line = AMP_RE.sub("", DIGIT_RE.sub("", line))
    # line = GT_RE.sub(">", LT_RE.sub("<", line))
    line = STOP_WORDS_RE.sub("", line)
    line = SPACE_RE.sub(' ', line.strip())
    print("modified line =", repr(line), file = sys.stderr)
    # line = POS_RE.sub(POS_CHAR + "\\1", line)
    # line = NEG_RE.sub(NEG_CHAR + "\\1", line)
    return line

def _iterlines(a_file):
    """Iterate over input lines of a file

    @param a_file - input file to iterate over

    @return iterator over resulting TSV fields

    """
    ifields = []
    for iline in a_file:
        iline = iline.decode(ENCODING)
        # compute prediction and append it to the list of fields
        ifields = get_fields(iline)
        ifields[TXT_IDX] = _cleanse(ifields[TXT_IDX])
        yield ifields

def _read_dataset(a_files):
    """Read data set into a list of two-tuples with input items and gold classes.

    @param a_files - input files containing training data

    @return list of 2-tuples with input items and their gold classes

    """
    return [([list(w) for w in [''.join(tokenize(ifields[TXT_IDX]))]], ifields[GLD_IDX]) \
            for ifile in a_files for ifields in _iterlines(ifile)]

def main():
    """Classify tweets according to their sentiment polarity

    @return \c 0 on success, non-0 other
    """
    # process CLI arguments
    argparser = argparse.ArgumentParser(description = """Script for classifying
tweets according to their sentiment polarity""")

    subparsers = argparser.add_subparsers(help="type of operation to perform", dest = "mode")
    # training options
    tr_parser = subparsers.add_parser(TRAIN, help = "train the model")
    tr_parser.add_argument("-d", "--dev-set", help = "development set",
                             type = argparse.FileType('r'))
    _add_cmn_options(tr_parser)
    # testing options
    test_parser = subparsers.add_parser(TEST, help = "test the model")
    test_parser.add_argument("-v", "--verbose", help = "output scores along with predicted labels",
                             action = "store_true")
    _add_cmn_options(test_parser)
    # evaluation options (train and test at the same time)
    ev_parser = subparsers.add_parser(EVALUATE, help = "evaluate trained model")
    _add_cmn_options(ev_parser)
    ev_parser.add_argument("-v", "--verbose", help = "output errors along with evaluation",
                           action = "store_true")
    args = argparser.parse_args()
    # perform the requied action
    if args.mode == TRAIN:
        classifier = SentimentClassifier(a_path = None)
        if args.dev_set is None:
            dev_set = None
        else:
            dev_set = _read_dataset([args.dev_set])
        classifier.train(_read_dataset(args.files), a_path = args.model, a_dev_set = dev_set)
    elif args.mode == TEST:
        # load model from default location
        y = ""; score = 0.
        classifier = SentimentClassifier()
        for ifile in args.files:
            for ifields in _iterlines(ifile):
                y, score = classifier.predict([list(w) for w in \
                                               [''.join(tokenize(ifields[TXT_IDX]))]])
                if args.verbose:
                    ifields.append(str(score))
                ifields.append(y)
                print(TAB.join(ifields))
    else:
        raise NotImplementedError
        # for ifile in a_files:
        #     macro_MAE, micro_MAE = evaluate(classify(classifier, ifile), args.verbose, lambda x: x)
        #     print("{:20s}{:.7}".format("Macro-averaged MAE:", macro_MAE), file = sys.stderr)
        #     print("{:20s}{:.7}".format("Micro-averaged MAE:", micro_MAE), file = sys.stderr)
    return 0

##################################################################
# Main
if __name__ == "__main__":
    main()
